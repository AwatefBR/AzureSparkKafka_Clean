name: CD - Deploy to Production

on:
  workflow_run:
    workflows:
      - CI - sbt assembly & Docker build
    types:
      - completed

jobs:
  deploy:
    if: ${{ github.event.workflow_run.conclusion == 'success' }}
    runs-on: ubuntu-latest

    permissions:
      contents: read
      packages: read

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.5.0

      - name: Configure Azure credentials
        uses: azure/login@v1
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}
        continue-on-error: true  # Fallback sur secrets si Terraform non configur√©

      - name: Get Infrastructure Values from Terraform
        id: terraform
        working-directory: infra
        continue-on-error: true
        env:
          TF_VAR_sql_admin_password: ${{ secrets.SQL_ADMIN_PASSWORD }}
        run: |
          # Essayer d'utiliser Terraform pour r√©cup√©rer les valeurs
          if terraform init -backend-config=backend-config.tfvars -input=false 2>/dev/null; then
            VM_IP=$(terraform output -raw vm_public_ip 2>/dev/null || echo "")
            SQL_FQDN=$(terraform output -raw sql_server_fqdn 2>/dev/null || echo "")
            
            if [ -n "$VM_IP" ] && [ -n "$SQL_FQDN" ]; then
              echo "‚úÖ Using Terraform outputs"
              echo "vm_ip=$VM_IP" >> $GITHUB_OUTPUT
              echo "sql_fqdn=$SQL_FQDN" >> $GITHUB_OUTPUT
              echo "use_terraform=true" >> $GITHUB_OUTPUT
            else
              echo "‚ö†Ô∏è  Terraform outputs not available, using secrets"
              echo "use_terraform=false" >> $GITHUB_OUTPUT
            fi
          else
            echo "‚ö†Ô∏è  Terraform not configured, using secrets"
            echo "use_terraform=false" >> $GITHUB_OUTPUT
          fi

      - name: Set deployment variables
        id: vars
        run: |
          # D√©terminer les valeurs √† utiliser (Terraform ou secrets)
          if [ "${{ steps.terraform.outputs.use_terraform }}" == "true" ]; then
            echo "VM_HOST=${{ steps.terraform.outputs.vm_ip }}" >> $GITHUB_OUTPUT
            echo "AZURE_SQL_SERVER=${{ steps.terraform.outputs.sql_fqdn }}" >> $GITHUB_OUTPUT
            echo "Using Terraform outputs" >> $GITHUB_STEP_SUMMARY
          else
            echo "VM_HOST=${{ secrets.VM_HOST }}" >> $GITHUB_OUTPUT
            echo "AZURE_SQL_SERVER=${{ secrets.AZURE_SQL_SERVER }}" >> $GITHUB_OUTPUT
            echo "Using GitHub secrets (Terraform not configured)" >> $GITHUB_STEP_SUMMARY
          fi

      - name: Deploy on VM via SSH
        uses: appleboy/ssh-action@v1.0.3
        env:
          GITHUB_REPOSITORY_OWNER: ${{ github.repository_owner }}
          GITHUB_REPOSITORY: ${{ github.repository }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          APP_TAG: main
          POSTGRES_DB: ${{ secrets.POSTGRES_DB }}
          POSTGRES_USER: ${{ secrets.POSTGRES_USER }}
          POSTGRES_PASSWORD: ${{ secrets.POSTGRES_PASSWORD }}
          PGADMIN_EMAIL: ${{ secrets.PGADMIN_EMAIL }}
          PGADMIN_PASSWORD: ${{ secrets.PGADMIN_PASSWORD }}
          KAFKA_BOOTSTRAP: ${{ secrets.KAFKA_BOOTSTRAP }}
          POSTGRES_HOST: ${{ secrets.POSTGRES_HOST }}
          POSTGRES_PORT: ${{ secrets.POSTGRES_PORT }}
          # Utiliser les valeurs d√©termin√©es dans l'√©tape pr√©c√©dente
          AZURE_SQL_SERVER: ${{ steps.vars.outputs.AZURE_SQL_SERVER }}
          AZURE_SQL_DB: ${{ secrets.AZURE_SQL_DB }}
          AZURE_SQL_USER: ${{ secrets.AZURE_SQL_USER }}
          AZURE_SQL_PASSWORD: ${{ secrets.AZURE_SQL_PASSWORD }}
        with:
          # Utiliser la valeur d√©termin√©e dans l'√©tape pr√©c√©dente
          host: ${{ steps.vars.outputs.VM_HOST }}
          username: ${{ secrets.VM_USER }}
          key: ${{ secrets.VM_SSH_KEY }}
          envs: GITHUB_REPOSITORY_OWNER,GITHUB_REPOSITORY,GITHUB_TOKEN,APP_TAG,POSTGRES_DB,POSTGRES_USER,POSTGRES_PASSWORD,PGADMIN_EMAIL,PGADMIN_PASSWORD,KAFKA_BOOTSTRAP,POSTGRES_HOST,POSTGRES_PORT,AZURE_SQL_SERVER,AZURE_SQL_DB,AZURE_SQL_USER,AZURE_SQL_PASSWORD
          script: |
            set -eo pipefail
            REPO_DIR="/home/azureuser/lol-streaming-clean"
            OWNER="$(echo "${GITHUB_REPOSITORY_OWNER:-${{ github.repository_owner }}}" | tr '[:upper:]' '[:lower:]')"
            REPO="$(basename "${GITHUB_REPOSITORY:-${{ github.repository }}}" | tr '[:upper:]' '[:lower:]')"

            cd "$REPO_DIR"

            if [ -f .env ]; then
              cp .env .env.bak
              echo ".env found, backup created: .env.bak"
            fi

            required_vars=(
              POSTGRES_DB POSTGRES_USER POSTGRES_PASSWORD
              PGADMIN_EMAIL PGADMIN_PASSWORD
              KAFKA_BOOTSTRAP POSTGRES_HOST POSTGRES_PORT
              AZURE_SQL_SERVER AZURE_SQL_DB AZURE_SQL_USER AZURE_SQL_PASSWORD
            )
            missing=0
            for v in "${required_vars[@]}"; do
              if [ -z "${!v:-}" ]; then
                echo "Missing required env var: $v"
                missing=1
              fi
            done
            if [ "$missing" -ne 0 ]; then
              echo "Aborting deploy due to missing secrets."
              exit 1
            fi

            cat > .env <<EOF
            OWNER=${OWNER}
            REPO=${REPO}
            POSTGRES_DB=${POSTGRES_DB}
            POSTGRES_USER=${POSTGRES_USER}
            POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
            PGADMIN_EMAIL=${PGADMIN_EMAIL}
            PGADMIN_PASSWORD=${PGADMIN_PASSWORD}
            KAFKA_BOOTSTRAP=${KAFKA_BOOTSTRAP}
            POSTGRES_HOST=${POSTGRES_HOST}
            POSTGRES_PORT=${POSTGRES_PORT}
            AZURE_SQL_SERVER=${AZURE_SQL_SERVER}
            AZURE_SQL_DB=${AZURE_SQL_DB}
            AZURE_SQL_USER=${AZURE_SQL_USER}
            AZURE_SQL_PASSWORD=${AZURE_SQL_PASSWORD}
            EOF

            echo "$GITHUB_TOKEN" | docker login ghcr.io -u "$OWNER" --password-stdin
            docker pull "ghcr.io/$OWNER/$REPO/producer:$APP_TAG"
            docker pull "ghcr.io/$OWNER/$REPO/consumer:$APP_TAG"

            # Remove leftover containers with fixed names to avoid conflicts.
            docker rm -f spark-master spark-worker 2>/dev/null || true
            
            echo "======================================="
            echo "   üî• RESET COMPLET ENV KAFKA + SPARK üî•"
            echo "======================================="

            ### 0. Arr√™t complet (sans supprimer les volumes pour l'instant)
            echo "üõë Arr√™t des containers..."
            docker compose down --remove-orphans

            ### 1. Purge des topics Kafka AVANT de supprimer les volumes
            echo "üí£ Suppression des topics Kafka..."
            docker compose up -d kafka zookeeper

            sleep 5

            # Utiliser kafka-topics (sans .sh) - commande Confluent Kafka 7.3.2
            # Filtrer uniquement les lignes qui sont des noms de topics valides
            topics=$(docker compose exec -T kafka kafka-topics --bootstrap-server kafka:9092 --list 2>&1 | grep -E "^[a-zA-Z0-9_-]+$" | grep -v "^__" || echo "")

            if [ -n "$topics" ]; then
              for t in $topics; do
                # Ignorer les topics syst√®me
                if [[ -n "$t" && ! "$t" =~ ^(__consumer_offsets|_schemas|__transaction_state) ]]; then
                  echo "   ‚Üí delete topic $t"
                  docker compose exec -T kafka kafka-topics --bootstrap-server kafka:9092 --delete --topic "$t" 2>/dev/null || true
                fi
              done
            else
              echo "   ‚Üí Aucun topic √† supprimer"
            fi

            docker compose down

            ### 2. Purge compl√®te des volumes li√©s au projet
            echo "üßπ Suppression des volumes Docker..."
            project_name=$(basename "$PWD" | tr '[:upper:]' '[:lower:]')

            # Supprimer les volumes nomm√©s explicitement
            docker volume rm -f "${project_name}_spark-checkpoints-players" 2>/dev/null || true
            docker volume rm -f "${project_name}_spark-checkpoints-players-stats" 2>/dev/null || true

            docker volume rm -f "${project_name}_spark-checkpoints-scoreboardplayers" 2>/dev/null || true
            docker volume rm -f "${project_name}_postgres-data" 2>/dev/null || true

            # Supprimer tous les volumes du projet (fallback)
            docker volume ls -q | grep "$project_name" | xargs -r docker volume rm -f || true

            ### 3. Purge des checkpoints Spark dans les volumes (si encore pr√©sents)
            echo "üóë Suppression checkpoints Spark dans volumes Docker..."
            for vol in $(docker volume ls -q | grep "spark-checkpoints"); do
              echo "   ‚Üí wipe volume $vol"
              docker run --rm -v $vol:/data busybox sh -c "rm -rf /data/*" 2>/dev/null || true
            done

            ### 4. Suppression des dossiers checkpoints locaux (si existent)
            echo "üóë Suppression des checkpoints Spark locaux..."
            rm -rf ./spark-checkpoints-* ./checkpoints 2>/dev/null || true

            ### 5. Purge des images de TON projet
            echo "‚ôªÔ∏è Suppression des images Docker du projet..."
            docker images | grep "$project_name" | awk '{print $3}' | xargs -r docker rmi -f || true

            ### 6. Purge des r√©seaux Docker (si orphelins)
            echo "üåê Nettoyage des r√©seaux Docker..."
            docker network prune -f

            # V√©rifier que PostgreSQL a bien charg√© le dump
            if docker compose exec -T postgres psql -U ${POSTGRES_USER:-postgres} -d ${POSTGRES_DB:-lol} -c "\dt" | grep -q "players\|scoreboardplayers"; then
              echo "‚úÖ PostgreSQL initialis√© avec succ√®s"
            else
              echo "‚ö†Ô∏è  PostgreSQL peut n√©cessiter une r√©initialisation manuelle"
            fi

            echo "======================================="
            echo "   ‚úÖ RESET TERMIN√â ‚Äî ENV CLEAN ‚úî"
            echo "======================================="

            docker compose -f docker-compose.prod.yml up -d --no-build
            docker compose -f docker-compose.prod.yml ps

            #CICD SHIT
README â€” Streaming temps rÃ©el League of Legends â†’ Azure SQL
 Objectif du projet

Ce projet met en place un pipeline de donnÃ©es temps rÃ©el basÃ© sur des donnÃ©es de matchs League of Legends.
Il collecte des informations provenant de lâ€™API Riot (players & scoreboard), les envoie dans Kafka, puis les consomme avec Spark Structured Streaming afin de les stocker dans Azure SQL Database.

Lâ€™objectif est de :

- Traiter des flux en continu

- Nettoyer / transformer les donnÃ©es avant stockage

- Rendre les donnÃ©es disponibles pour lâ€™analyse & la BI (Power BI)


Services deployÃ©s via Docker Compose :

| Service               | RÃ´le                                                 |
| --------------------- | ---------------------------------------------------- |
| `players-producer`    | RÃ©cupÃ¨re les infos joueurs + stats                   |
| `scoreboard-producer` | RÃ©cupÃ¨re les infos du scoreboard en match            |
| `kafka`               | Message broker pour le streaming                     |
| `zookeeper`           | NÃ©cessaire au fonctionnement de Kafka                |
| `spark-master`        | Master du cluster Spark                              |
| `spark-worker`        | Worker exÃ©cutant les tÃ¢ches Spark                    |
| `spark-consumer`      | Lit Kafka, transforme & Ã©crit dans Azure SQL         |
| `kafka-ui`            | Interface graphique pour visualiser les topics Kafka |

|PrÃ©-requis
| Logiciel       | Version    |
| -------------- | ---------- |
| Docker         | â‰¥ 24       |
| Docker Compose | â‰¥ 2        |
| Scala          | 2.12       |
| SBT            | â‰¥ 1.8      |
| Java           | OpenJDK 11 |

Azure SQL doit Ãªtre accessible en public et la white-list IP configurÃ©e.

 DÃ©marrer le pipeline

Compiler & packager le consumer Spark:

sbt clean assembly

La commande gÃ©nÃ¨re le jar :
target/scala-2.12/lol-streaming-assembly-0.1.0.jar

(Re)build des images Docker:

docker compose build

Lancer le cluster + producers + consumer:

docker compose up -d

VÃ©rifier que tout fonctionne:

docker compose ps

Consulter les logs (exemples):

docker logs -f lol-streaming-clean-spark-consumer-1
docker logs -f lol-streaming-clean-players-producer-1
docker logs -f lol-streaming-clean-scoreboard-producer-1

 ArrÃªter l'ensemble
docker compose down

Durant le run:
Si l'espace disk est saturÃ©
Check : df -h (si 100%) --> supprimer les conteneurs arrÃ©tÃ©s, images inutilisÃ©es, volumes non attachÃ©s --> docker system prune -a --volumes


Tout relancer (base propre) :
docker compose down -v --remove-orphans
sleep 5
docker system prune -af
sleep 5
docker volume prune -f
sleep 5
docker network prune -f
sleep 5
sbt clean assembly
sleep 5
docker compose build --no-cache
sleep 5
docker compose up -d
sleep 5


verifier que les topics existent :

docker exec -it lol-streaming-clean-kafka-1 kafka-topics \
  --bootstrap-server kafka:9092 --list

creer les topics manuellement:

docker exec -it lol-streaming-clean-kafka-1 kafka-topics \
  --create --topic players \
  --bootstrap-server kafka:9092 \
  --partitions 1 --replication-factor 1

docker exec -it lol-streaming-clean-kafka-1 kafka-topics \
  --create --topic scoreboard \
  --bootstrap-server kafka:9092 \
  --partitions 1 --replication-factor 1


Effacer les ckp defectueux

sudo rm -rf /tmp/checkpoints/scoreboard
sudo rm -rf /tmp/checkpoints/players

docker compose down
sudo rm -rf /tmp/checkpoints /tmp/spark*
docker system prune -a --volumes -f
sudo systemctl restart docker

tout supprimer y compris les volumes persistants
docker-compose down -v


SELECT *
FROM dbo.Scoreboard
ORDER BY CAST(id AS INT)
LIMIT 100 

java.io.IOException: No space left on device
ðŸ§© InterprÃ©tation
Spark (ou ton container Docker) nâ€™a plus dâ€™espace disque disponible pour :

Ã©crire ses fichiers temporaires (/tmp, /tmp/blockmgr-...)

stocker les checkpoints Spark

ou Ã©ventuellement gÃ©rer les shuffle / cache intermÃ©diaires.

Câ€™est une erreur du systÃ¨me de fichiers, pas une erreur applicative Spark.
# Bonnes Pratiques : MERGE avec Spark Streaming et Azure SQL

## üîç Pourquoi les autres consumers fonctionnent

### `SparkToAzureSql` (Players et Scoreboard)

**Approche utilis√©e** :
```scala
batchDF.write
  .format("jdbc")
  .mode("append")  // ‚Üê Simple INSERT
  .save()
```

**Pourquoi √ßa fonctionne** :
1. **Mode append simple** : Ins√®re de nouvelles lignes sans v√©rifier les doublons
2. **D√©duplication avant √©criture** : Utilise `dropDuplicates()` sur `uniqueline` ou `overviewpage` AVANT l'√©criture
3. **Pas de contrainte PRIMARY KEY** : Les tables `dbo.Players` et `dbo.Scoreboard` acceptent potentiellement des doublons, ou la d√©duplication est faite en amont
4. **Pas besoin de MERGE** : Chaque ligne est trait√©e comme nouvelle

### `PlayersStats` - Pourquoi MERGE est n√©cessaire

**Probl√®me** :
- Agr√©gation par `playerName` ‚Üí un seul enregistrement par joueur
- Table `dbo.PlayerStats` avec `playerName` comme PRIMARY KEY
- Mode `outputMode("update")` ‚Üí doit UPDATE si existe, INSERT sinon
- **Besoin de MERGE** pour √©viter les erreurs de cl√© primaire

## ‚ùå Probl√®me avec l'approche actuelle

### Tables temporaires locales (`#temp`)

```scala
val tempTable = s"#temp_${batchId}_${System.currentTimeMillis()}"
```

**Pourquoi √ßa ne fonctionne pas** :
1. **Tables temporaires locales** (`#temp`) sont **visibles uniquement dans la session JDBC qui les cr√©e**
2. Spark JDBC √©crit dans une session ‚Üí table cr√©√©e dans session A
3. Connection JDBC pour MERGE = nouvelle session B ‚Üí **ne voit pas la table**
4. Erreur : `Invalid object name '#temp_...'`

## ‚úÖ Bonnes Pratiques pour MERGE avec Spark + Azure SQL

### Option 1 : Table temporaire globale (Recommand√©)

```scala
val tempTable = s"##temp_${batchId}_${System.currentTimeMillis()}"
```

**Avantages** :
- Tables `##temp` (double `#`) sont **globales** et visibles par toutes les sessions
- Simple √† impl√©menter
- Nettoyage automatique √† la fermeture de la connexion

**Inconv√©nients** :
- Peut causer des conflits si plusieurs batches s'ex√©cutent en parall√®le (rare avec streaming)

### Option 2 : Table permanente temporaire (Plus s√ªr)

```scala
val tempTable = s"temp_merge_${batchId}_${System.currentTimeMillis()}"
// Table normale (pas temporaire)
// Nettoyage explicite apr√®s MERGE
```

**Avantages** :
- Pas de probl√®me de visibilit√© entre sessions
- Contr√¥le total sur le cycle de vie
- Pas de conflits entre batches

**Inconv√©nients** :
- N√©cessite un nettoyage explicite
- Peut laisser des tables orphelines en cas d'erreur

### Option 3 : MERGE direct avec batch (Plus complexe)

√âviter la table temporaire en faisant le MERGE directement ligne par ligne :

```scala
// Pour chaque ligne du DataFrame
batchDF.foreachPartition { partition =>
  val conn = DriverManager.getConnection(...)
  partition.foreach { row =>
    // MERGE pour chaque ligne
    val mergeSQL = s"""
      MERGE INTO $tableName AS target
      USING (VALUES (...)) AS source(...)
      ON target.playerName = source.playerName
      ...
    """
    conn.createStatement().executeUpdate(mergeSQL)
  }
}
```

**Avantages** :
- Pas de table temporaire
- Plus de contr√¥le

**Inconv√©nients** :
- Plus lent (un MERGE par ligne)
- Plus complexe
- Risque de timeout sur grandes tables

### Option 4 : Utiliser une table staging permanente

Cr√©er une table staging permanente, y √©crire, faire le MERGE, puis truncate :

```scala
val stagingTable = "dbo.PlayerStats_Staging"
// √âcrire dans staging
// MERGE FROM staging TO target
// TRUNCATE staging
```

**Avantages** :
- Pas de probl√®me de visibilit√©
- R√©utilisable
- Performant

**Inconv√©nients** :
- N√©cessite une table suppl√©mentaire
- Gestion de la table staging

## üéØ Solution Recommand√©e : Table Temporaire Globale

Pour votre cas, la **Option 1** (table temporaire globale `##temp`) est la meilleure :

```scala
private def writeWithUpsert(batchDF: DataFrame, tableName: String, batchId: Long): Unit = {
    // Utiliser ## (double #) pour table temporaire GLOBALE
    val tempTable = s"##temp_${batchId}_${System.currentTimeMillis()}"
    
    // 1. √âcrire dans table temporaire globale
    batchDF.write
        .format("jdbc")
        .option("url", Config.azureJdbcUrl)
        .option("driver", "com.microsoft.sqlserver.jdbc.SQLServerDriver")
        .option("dbtable", tempTable)
        .option("user", Config.azureUser)
        .option("password", Config.azurePassword)
        .mode("overwrite")
        .save()

    // 2. MERGE depuis la table temporaire globale
    var conn: Connection = null
    var stmt: Statement = null
    try {
        Class.forName("com.microsoft.sqlserver.jdbc.SQLServerDriver")
        conn = DriverManager.getConnection(Config.azureJdbcUrl, Config.azureUser, Config.azurePassword)
        stmt = conn.createStatement()

        val mergeSQL = s"""
            MERGE INTO $tableName AS target
            USING $tempTable AS source
            ON target.playerName = source.playerName
            WHEN MATCHED THEN
                UPDATE SET
                    avg_kills = source.avg_kills,
                    avg_deaths = source.avg_deaths,
                    avg_assists = source.avg_assists,
                    sum_kills = source.sum_kills,
                    sum_deaths = source.sum_deaths,
                    sum_assists = source.sum_assists,
                    avg_kda = source.avg_kda,
                    games_played = source.games_played,
                    kda_from_sums = source.kda_from_sums,
                    updated_at = source.updated_at
            WHEN NOT MATCHED THEN
                INSERT (playerName, avg_kills, avg_deaths, avg_assists, sum_kills, sum_deaths, sum_assists, avg_kda, games_played, kda_from_sums, updated_at)
                VALUES (source.playerName, source.avg_kills, source.avg_deaths, source.avg_assists, source.sum_kills, source.sum_deaths, source.sum_assists, source.avg_kda, source.games_played, source.kda_from_sums, source.updated_at);
        """

        val rowsAffected = stmt.executeUpdate(mergeSQL)
        println(s"[Azure] üîÑ MERGE ex√©cut√© : $rowsAffected lignes affect√©es")

        // Nettoyer (optionnel, se fait automatiquement √† la fermeture de connexion)
        stmt.executeUpdate(s"DROP TABLE IF EXISTS $tempTable")
    } finally {
        if (stmt != null) stmt.close()
        if (conn != null) conn.close()
    }
}
```

## üìä Comparaison des approches

| Approche | Complexit√© | Performance | Fiabilit√© | Recommand√© |
|----------|------------|-------------|-----------|------------|
| `##temp` (globale) | ‚≠ê Simple | ‚≠ê‚≠ê‚≠ê Excellente | ‚≠ê‚≠ê‚≠ê Tr√®s fiable | ‚úÖ Oui |
| Table permanente | ‚≠ê‚≠ê Moyenne | ‚≠ê‚≠ê‚≠ê Excellente | ‚≠ê‚≠ê Bonne | ‚ö†Ô∏è Si besoin |
| MERGE ligne par ligne | ‚≠ê‚≠ê‚≠ê Complexe | ‚≠ê Lente | ‚≠ê‚≠ê Bonne | ‚ùå Non |
| Table staging | ‚≠ê‚≠ê Moyenne | ‚≠ê‚≠ê‚≠ê Excellente | ‚≠ê‚≠ê‚≠ê Tr√®s fiable | ‚úÖ Si r√©utilisable |

## üîë Points Cl√©s

1. **Tables `#temp` (locale)** = visible uniquement dans la session qui les cr√©e
2. **Tables `##temp` (globale)** = visible par toutes les sessions
3. **Spark JDBC** cr√©e une session diff√©rente de votre Connection JDBC
4. **Solution** : Utiliser `##temp` pour que les deux sessions voient la table




# Monitoring et Reset du Consumer PlayersStats

## ğŸ“Š Monitoring AjoutÃ©

Le consumer `PlayersStats` affiche maintenant dans les logs :

```
[PlayersStats] ğŸ“Š Batch 29 â†’
  - Joueurs dans le batch: 15
  - Matchs dans le batch: 45
  - Joueurs uniques totaux: 308
  - Matchs traitÃ©s totaux: 1250
  - Ã‰criture vers Azure SQL (MERGE/UPSERT)...
[Azure] ğŸ”„ MERGE exÃ©cutÃ© : 15 lignes affectÃ©es
[PlayersStats] âœ… Batch 29 terminÃ©
```

### MÃ©triques disponibles :
- **Joueurs dans le batch** : Nombre de joueurs uniques dans le batch actuel
- **Matchs dans le batch** : Nombre total de matchs traitÃ©s dans ce batch (somme des `games_played`)
- **Joueurs uniques totaux** : Nombre cumulÃ© de joueurs uniques vus depuis le dÃ©marrage
- **Matchs traitÃ©s totaux** : Nombre cumulÃ© de matchs traitÃ©s depuis le dÃ©marrage

## ğŸ”§ Corrections ApportÃ©es

### 1. ProblÃ¨me de clÃ© primaire dupliquÃ©e âœ…
**Avant** : Utilisait `mode("append")` â†’ erreur `PRIMARY KEY constraint violation`
**Maintenant** : Utilise `MERGE` SQL pour faire un UPSERT (UPDATE si existe, INSERT sinon)

### 2. Monitoring âœ…
Ajout de logs dÃ©taillÃ©s pour suivre :
- Nombre de joueurs traitÃ©s
- Nombre de matchs traitÃ©s
- Statistiques par batch

## ğŸ”„ Reset du Consumer (Repartir depuis le dÃ©but)

### Question : Si on supprime la base, le consumer va-t-il recommencer depuis le dÃ©but ?

**RÃ©ponse** : **NON**, car le checkpoint Kafka est stockÃ© sÃ©parÃ©ment.

### Pourquoi ?
Le checkpoint est stockÃ© dans `/checkpoints/playerstats` (dans le volume Docker). MÃªme si vous supprimez la table `dbo.PlayerStats` dans Azure SQL, le checkpoint Kafka reste et le consumer reprendra lÃ  oÃ¹ il s'Ã©tait arrÃªtÃ©.

### Comment repartir depuis le dÃ©but ?

#### Option 1 : Supprimer le checkpoint (recommandÃ©)
```bash
# Sur la VM ou dans le conteneur
docker exec -it <container-consumer> rm -rf /checkpoints/playerstats

# Ou depuis la VM si le volume est montÃ©
sudo rm -rf /var/lib/docker/volumes/<volume-name>/_data/playerstats
```

#### Option 2 : Supprimer le volume Docker
```bash
# Lister les volumes
docker volume ls | grep checkpoint

# Supprimer le volume
docker volume rm <volume-name>
```

#### Option 3 : Via docker-compose
```bash
# ArrÃªter le service
docker compose stop spark-consumer-players-stats

# Supprimer le volume
docker compose down -v

# RedÃ©marrer (crÃ©era un nouveau volume vide)
docker compose up -d spark-consumer-players-stats
```

### VÃ©rifier le checkpoint actuel
```bash
# Dans le conteneur
docker exec -it <container-consumer> ls -la /checkpoints/playerstats

# Voir les offsets Kafka stockÃ©s
docker exec -it <container-consumer> cat /checkpoints/playerstats/sources/0/*/metadata
```

## ğŸ“ Workflow Complet de Reset

### 1. ArrÃªter le consumer
```bash
docker compose stop spark-consumer-players-stats
```

### 2. Supprimer la table Azure SQL (optionnel)
```sql
-- Dans Azure SQL
DROP TABLE dbo.PlayerStats;
```

### 3. Supprimer le checkpoint
```bash
# Option A : Supprimer le volume
docker compose down -v

# Option B : Supprimer manuellement
docker exec -it spark-consumer-players-stats rm -rf /checkpoints/playerstats
```

### 4. RedÃ©marrer le consumer
```bash
docker compose up -d spark-consumer-players-stats
```

### 5. VÃ©rifier les logs
```bash
docker compose logs -f spark-consumer-players-stats
```

Vous devriez voir :
```
[PlayersStats] ğŸš€ DÃ©marrage du job PlayersStats (streaming)
[PlayersStats] ğŸ“Š Batch 0 â†’
  - Joueurs dans le batch: X
  - Matchs dans le batch: Y
  ...
```

## âš ï¸ Important

- **Checkpoint = Position dans Kafka** : Le checkpoint stocke l'offset Kafka, pas l'Ã©tat de la base de donnÃ©es
- **Supprimer la base â‰  Reset Kafka** : Pour repartir depuis le dÃ©but, il faut supprimer le checkpoint
- **Perte de donnÃ©es** : Supprimer le checkpoint fait perdre la position, le consumer repartira depuis `startingOffsets` (actuellement `"latest"`)

## ğŸ” VÃ©rifier le nombre de joueurs dans Azure SQL

```sql
-- Compter les joueurs
SELECT COUNT(*) as total_players FROM dbo.PlayerStats;

-- Voir les statistiques
SELECT 
    COUNT(*) as total_players,
    SUM(games_played) as total_games,
    AVG(avg_kda) as avg_kda_overall
FROM dbo.PlayerStats;
```

## ğŸ“ˆ Monitoring en Temps RÃ©el

Pour suivre les logs en temps rÃ©el :
```bash
docker compose logs -f spark-consumer-players-stats | grep -E "PlayersStats|Azure"
```

